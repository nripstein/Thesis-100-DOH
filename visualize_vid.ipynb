{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7262/2532042905.py:113: RuntimeWarning: invalid value encountered in cast\n",
      "  predictions.map({\"Portable Object\": 1, \"No Contact\": 0 , \"Stationary Object Contact\": 0}).to_numpy().astype(np.int8),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3851 frames 3851 labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3851/3851 [01:25<00:00, 45.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 571)\n",
      "writing video...\n",
      "saved video @  /home/nripstein/Documents/thesis data/thesis labels/sv labels/sv2_frames/video_with_predictions.mp4\n",
      "(3591,)\n"
     ]
    }
   ],
   "source": [
    "# from https://github.com/TalIfargan/action_segmentation_for_surgical_data/blob/main/video_maker.py\n",
    "action_map = {\"G0\": \"No Gesture\",\n",
    "              \"G1\": \"Needle Passing\",\n",
    "              \"G2\": \"Pull the Suture\",\n",
    "              \"G3\": \"Instrument Tie\",\n",
    "              \"G4\": \"Lay the Knot\" ,\n",
    "              \"G5\": \"Cut the Suture\"}\n",
    "\n",
    "\n",
    "action_map = {True: \"contact\",\n",
    "              False: \"non-contact\"}\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "fontScale = 2\n",
    "color = (255, 0, 0)\n",
    "thickness = 2\n",
    "\n",
    "\n",
    "def add_segmentation(img, i, base, v2, num_frames, gt):\n",
    "    #frame = cv2.imread(img)\n",
    "    frame = img\n",
    "    width = frame.shape[1]\n",
    "    height = frame.shape[0]\n",
    "    # base = cv2.imread(base)\n",
    "    # v2 = cv2.imread(v2)\n",
    "    left_size = 150\n",
    "\n",
    "    patch_header = np.full((200, v2.shape[1], v2.shape[2]), 255, dtype=np.uint8)\n",
    "    patch_header = cv2.putText(patch_header, f'GT: {gt}', (500, 80), font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "    header_left = np.full((patch_header.shape[0], left_size, patch_header.shape[2]), 255, dtype=np.uint8)\n",
    "    frame_relative_part = int((i / num_frames) * patch_header.shape[1])\n",
    "    patch_header[120:, frame_relative_part - 1:frame_relative_part + 1, :] = 0\n",
    "    header_final = cv2.hconcat([header_left, patch_header])\n",
    "    header_final = cv2.resize(header_final, (width, int((width / header_final.shape[1]) * header_final.shape[0])), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    patch_1 = v2[:v2.shape[0] // 2, :, :]\n",
    "\n",
    "    patch_1_left = np.full((patch_1.shape[0], left_size, patch_1.shape[2]), 255, dtype=np.uint8)\n",
    "    patch_1_left = cv2.putText(patch_1_left, 'GT', (50, 65), font, 1, (32, 32, 32), thickness, cv2.LINE_AA)\n",
    "    patch_1_left = cv2.putText(patch_1_left, 'V2', (50, 180), font, 1, (32, 32, 32), thickness, cv2.LINE_AA)\n",
    "    patch_1_final = cv2.hconcat([patch_1_left, patch_1])\n",
    "    patch_1_final = cv2.resize(patch_1_final, (width, int((width / patch_1_final.shape[1]) * patch_1_final.shape[0])), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    patch_2 = base[base.shape[0] // 4:base.shape[0] // 2, :, :]\n",
    "    patch_2_left = np.full((patch_2.shape[0], left_size, patch_2.shape[2]), 255, dtype=np.uint8)\n",
    "    patch_2_left = cv2.putText(patch_2_left, 'Baseline', (10, 70), font, 1, (32, 32, 32), thickness, cv2.LINE_AA)\n",
    "    patch_2_final = cv2.hconcat([patch_2_left, patch_2])\n",
    "    patch_2_final = cv2.resize(patch_2_final, (width, int((width / patch_2_final.shape[1]) * patch_2_final.shape[0])), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    image_with_patch = cv2.vconcat([frame, header_final, patch_1_final, patch_2_final])\n",
    "    \n",
    "    return image_with_patch\n",
    "\n",
    "def image_seq_to_segmentation_video(images_path, baseline_path, v2_path, gts, output_path='./video.mp4', fps=30.0):\n",
    "    img_array = []\n",
    "    # loop over all frames\n",
    "    \n",
    "    base = cv2.imread(baseline_path)\n",
    "    v2 = cv2.imread(v2_path)\n",
    "    frames = sorted(os.listdir(images_path))\n",
    "    num_frames = len(frames)\n",
    "    print(num_frames, \"frames\", len(gts), \"labels\")\n",
    "    assert len(frames) == len(gts), \"Number of frames does not match number of labels\"\n",
    "    for i, filename in enumerate(tqdm(frames)):\n",
    "        # print(f'frame {i} of video in {images_path}')\n",
    "        img = cv2.imread(os.path.join(images_path, filename))\n",
    "        height, width, layers = img.shape\n",
    "        image_with_segmentation = add_segmentation(img, i, base, v2, num_frames, gts[i])\n",
    "        img_array.append(image_with_segmentation)\n",
    "\n",
    "    size = (img_array[0].shape[1], img_array[0].shape[0])\n",
    "    print(size)\n",
    "    print(\"writing video...\")\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Be sure to use lower case\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, size)\n",
    "\n",
    "    for i in range(len(img_array)):\n",
    "        out.write(img_array[i])\n",
    "    out.release()\n",
    "    print(\"saved video @ \", output_path)\n",
    "\n",
    "def extract_labels(labels_file):\n",
    "    file_ptr = open(labels_file, 'r')\n",
    "    gt_file_content = file_ptr.read().split('\\n')[:-1]\n",
    "    content = []\n",
    "    for item in gt_file_content:\n",
    "        splitted_item = item.split()\n",
    "        content += [splitted_item[2]]*(int(splitted_item[1]) - int(splitted_item[0]) + 1)\n",
    "    return [action_map[item] for item in content]\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "sv2_dir = \"/home/nripstein/Documents/thesis data/thesis labels/sv labels/sv2_frames/\"\n",
    "sv2_gt_tuples = pd.read_csv(sv2_dir + \"sv2_frames_labels.csv\")\n",
    "sv2_pred = pd.read_csv(sv2_dir + \"sv2_pred.csv\")\n",
    "sv2_pred = sv2_pred.rename(columns={\"image\": \"frame_id\", \"contact_label\": \"contact_label_pred\"})\n",
    "# display(sv2_pred)\n",
    "# display(sv2_gt)\n",
    "\n",
    "sv2_merged = pd.merge(sv2_gt_tuples, sv2_pred, on='frame_id', how='inner')\n",
    "sv2_dir = \"/home/nripstein/Documents/thesis data/thesis labels/sv labels/sv2_frames/\"\n",
    "images_path = sv2_dir + \"sv2_shrunk\"\n",
    "output_path = sv2_dir + 'video_with_predictions.mp4'\n",
    "fps = 60  # Adjust FPS as needed\n",
    "\n",
    "\n",
    "gts = sv2_merged[\"label\"]\n",
    "predictions = sv2_pred[\"contact_label_pred\"]\n",
    "# gts.map({\"not_holding\": 0, \"holding\": 1}).to_numpy().astype(np.int8),\n",
    "# image_seq_to_segmentation_video(images_path, \"sv2_pred.png\", \"sv2_pred.png\", \"sv2_gt.png\", output_path, fps=fps)\n",
    "\n",
    "image_seq_to_segmentation_video(images_path,\n",
    "                                \"sv2_pred.png\",\n",
    "                                \"sv2_pred.png\",\n",
    "                                predictions.map({\"Portable Object\": 1, \"No Contact\": 0 , \"Stationary Object Contact\": 0}).to_numpy().astype(np.int8),\n",
    "                                # gts.map({\"not_holding\": 0, \"holding\": 1}).to_numpy().astype(np.int8),\n",
    "                                output_path,\n",
    "                                fps=fps)\n",
    "\n",
    "print(gts.map({\"not_holding\": 0, \"holding\": 1}).to_numpy().astype(np.int8).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# if __name__ == '__main__':\n",
    "#     gts = [os.path.join('data', 'transcriptions_gestures', vid+'.txt') for vid in ['P020_balloon1', 'P032_tissue1', 'P038_balloon2']]\n",
    "#     gts = [extract_labels(item) for item in gts]\n",
    "#     images_paths = ['/datashare/APAS/frames/P020_balloon1_side', '/datashare/APAS/frames/P032_tissue1_side', '/datashare/APAS/frames/P038_balloon2_side']\n",
    "#     baseline_segmentations = ['results/split_0/P020_balloon1_stage3.png', 'results/split_2/P032_tissue1_stage3.png', 'results/split_4/P038_balloon2_stage3.png']\n",
    "#     advanced_segmentations = ['results_v2_hidden_1280/split_0/P020_balloon1_stage3.png', 'results_v2_hidden_1280/split_2/P032_tissue1_stage3.png', 'results_v2_hidden_1280/split_4/P038_balloon2_stage3.png']\n",
    "#     for i in range(3):\n",
    "#         image_seq_to_segmentation_video(images_paths[i], baseline_segmentations[i], advanced_segmentations[i], gts[i], f'videos/{images_paths[i].split(\"/\")[-1]}.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame_id</th>\n",
       "      <th>contact_label_pred</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_sv2.jpg</td>\n",
       "      <td>Stationary Object Contact</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_sv2.jpg</td>\n",
       "      <td>Stationary Object Contact</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2_sv2.jpg</td>\n",
       "      <td>Stationary Object Contact</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3_sv2.jpg</td>\n",
       "      <td>Stationary Object Contact</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4_sv2.jpg</td>\n",
       "      <td>Stationary Object Contact</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3846</th>\n",
       "      <td>3846_sv2.jpg</td>\n",
       "      <td>Stationary Object Contact</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3847</th>\n",
       "      <td>3847_sv2.jpg</td>\n",
       "      <td>Stationary Object Contact</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3848</th>\n",
       "      <td>3848_sv2.jpg</td>\n",
       "      <td>Stationary Object Contact</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3849</th>\n",
       "      <td>3849_sv2.jpg</td>\n",
       "      <td>Stationary Object Contact</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3850</th>\n",
       "      <td>3850_sv2.jpg</td>\n",
       "      <td>Stationary Object Contact</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3851 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          frame_id         contact_label_pred  probability\n",
       "0        0_sv2.jpg  Stationary Object Contact           99\n",
       "1        1_sv2.jpg  Stationary Object Contact           99\n",
       "2        2_sv2.jpg  Stationary Object Contact           99\n",
       "3        3_sv2.jpg  Stationary Object Contact           99\n",
       "4        4_sv2.jpg  Stationary Object Contact           99\n",
       "...            ...                        ...          ...\n",
       "3846  3846_sv2.jpg  Stationary Object Contact           99\n",
       "3847  3847_sv2.jpg  Stationary Object Contact           99\n",
       "3848  3848_sv2.jpg  Stationary Object Contact           99\n",
       "3849  3849_sv2.jpg  Stationary Object Contact           99\n",
       "3850  3850_sv2.jpg  Stationary Object Contact           99\n",
       "\n",
       "[3851 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>frame_id</th>\n",
       "      <th>label</th>\n",
       "      <th>fps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sv2_frames</td>\n",
       "      <td>0_sv2.jpg</td>\n",
       "      <td>not_holding</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sv2_frames</td>\n",
       "      <td>1_sv2.jpg</td>\n",
       "      <td>not_holding</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sv2_frames</td>\n",
       "      <td>2_sv2.jpg</td>\n",
       "      <td>not_holding</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sv2_frames</td>\n",
       "      <td>3_sv2.jpg</td>\n",
       "      <td>not_holding</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sv2_frames</td>\n",
       "      <td>4_sv2.jpg</td>\n",
       "      <td>not_holding</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3586</th>\n",
       "      <td>sv2_frames</td>\n",
       "      <td>3586_sv2.jpg</td>\n",
       "      <td>holding</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3587</th>\n",
       "      <td>sv2_frames</td>\n",
       "      <td>3587_sv2.jpg</td>\n",
       "      <td>holding</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3588</th>\n",
       "      <td>sv2_frames</td>\n",
       "      <td>3588_sv2.jpg</td>\n",
       "      <td>holding</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3589</th>\n",
       "      <td>sv2_frames</td>\n",
       "      <td>3589_sv2.jpg</td>\n",
       "      <td>holding</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3590</th>\n",
       "      <td>sv2_frames</td>\n",
       "      <td>3590_sv2.jpg</td>\n",
       "      <td>holding</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3591 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        video_id      frame_id        label  fps\n",
       "0     sv2_frames     0_sv2.jpg  not_holding   60\n",
       "1     sv2_frames     1_sv2.jpg  not_holding   60\n",
       "2     sv2_frames     2_sv2.jpg  not_holding   60\n",
       "3     sv2_frames     3_sv2.jpg  not_holding   60\n",
       "4     sv2_frames     4_sv2.jpg  not_holding   60\n",
       "...          ...           ...          ...  ...\n",
       "3586  sv2_frames  3586_sv2.jpg      holding   60\n",
       "3587  sv2_frames  3587_sv2.jpg      holding   60\n",
       "3588  sv2_frames  3588_sv2.jpg      holding   60\n",
       "3589  sv2_frames  3589_sv2.jpg      holding   60\n",
       "3590  sv2_frames  3590_sv2.jpg      holding   60\n",
       "\n",
       "[3591 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>frame_id</th>\n",
       "      <th>label</th>\n",
       "      <th>fps</th>\n",
       "      <th>contact_label_pred</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sv2_frames</td>\n",
       "      <td>0_sv2.jpg</td>\n",
       "      <td>not_holding</td>\n",
       "      <td>60</td>\n",
       "      <td>Stationary Object Contact</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sv2_frames</td>\n",
       "      <td>1_sv2.jpg</td>\n",
       "      <td>not_holding</td>\n",
       "      <td>60</td>\n",
       "      <td>Stationary Object Contact</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sv2_frames</td>\n",
       "      <td>2_sv2.jpg</td>\n",
       "      <td>not_holding</td>\n",
       "      <td>60</td>\n",
       "      <td>Stationary Object Contact</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sv2_frames</td>\n",
       "      <td>3_sv2.jpg</td>\n",
       "      <td>not_holding</td>\n",
       "      <td>60</td>\n",
       "      <td>Stationary Object Contact</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sv2_frames</td>\n",
       "      <td>4_sv2.jpg</td>\n",
       "      <td>not_holding</td>\n",
       "      <td>60</td>\n",
       "      <td>Stationary Object Contact</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3586</th>\n",
       "      <td>sv2_frames</td>\n",
       "      <td>3586_sv2.jpg</td>\n",
       "      <td>holding</td>\n",
       "      <td>60</td>\n",
       "      <td>Portable Object</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3587</th>\n",
       "      <td>sv2_frames</td>\n",
       "      <td>3587_sv2.jpg</td>\n",
       "      <td>holding</td>\n",
       "      <td>60</td>\n",
       "      <td>Portable Object</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3588</th>\n",
       "      <td>sv2_frames</td>\n",
       "      <td>3588_sv2.jpg</td>\n",
       "      <td>holding</td>\n",
       "      <td>60</td>\n",
       "      <td>Portable Object</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3589</th>\n",
       "      <td>sv2_frames</td>\n",
       "      <td>3589_sv2.jpg</td>\n",
       "      <td>holding</td>\n",
       "      <td>60</td>\n",
       "      <td>Portable Object</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3590</th>\n",
       "      <td>sv2_frames</td>\n",
       "      <td>3590_sv2.jpg</td>\n",
       "      <td>holding</td>\n",
       "      <td>60</td>\n",
       "      <td>Portable Object</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3591 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        video_id      frame_id        label  fps         contact_label_pred  \\\n",
       "0     sv2_frames     0_sv2.jpg  not_holding   60  Stationary Object Contact   \n",
       "1     sv2_frames     1_sv2.jpg  not_holding   60  Stationary Object Contact   \n",
       "2     sv2_frames     2_sv2.jpg  not_holding   60  Stationary Object Contact   \n",
       "3     sv2_frames     3_sv2.jpg  not_holding   60  Stationary Object Contact   \n",
       "4     sv2_frames     4_sv2.jpg  not_holding   60  Stationary Object Contact   \n",
       "...          ...           ...          ...  ...                        ...   \n",
       "3586  sv2_frames  3586_sv2.jpg      holding   60            Portable Object   \n",
       "3587  sv2_frames  3587_sv2.jpg      holding   60            Portable Object   \n",
       "3588  sv2_frames  3588_sv2.jpg      holding   60            Portable Object   \n",
       "3589  sv2_frames  3589_sv2.jpg      holding   60            Portable Object   \n",
       "3590  sv2_frames  3590_sv2.jpg      holding   60            Portable Object   \n",
       "\n",
       "      probability  \n",
       "0              99  \n",
       "1              99  \n",
       "2              99  \n",
       "3              99  \n",
       "4              99  \n",
       "...           ...  \n",
       "3586           99  \n",
       "3587           99  \n",
       "3588           99  \n",
       "3589           99  \n",
       "3590           99  \n",
       "\n",
       "[3591 rows x 6 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "sv2_dir = \"/home/nripstein/Documents/thesis data/thesis labels/sv labels/sv2_frames/\"\n",
    "sv2_gt_tuples = pd.read_csv(sv2_dir + \"sv2_frames_labels.csv\")\n",
    "sv2_pred = pd.read_csv(sv2_dir + \"sv2_pred.csv\")\n",
    "sv2_pred = sv2_pred.rename(columns={\"image\": \"frame_id\", \"contact_label\": \"contact_label_pred\"})\n",
    "display(sv2_pred)\n",
    "display(sv2_gt_tuples)\n",
    "\n",
    "sv2_merged = pd.merge(sv2_gt_tuples, sv2_pred, on='frame_id', how='inner')\n",
    "sv2_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3851 frames\n",
      "frame 0 of video in /home/nripstein/Documents/thesis data/thesis labels/sv labels/sv2_frames/sv2_shrunk\n",
      "frame 1 of video in /home/nripstein/Documents/thesis data/thesis labels/sv labels/sv2_frames/sv2_shrunk\n",
      "frame 2 of video in /home/nripstein/Documents/thesis data/thesis labels/sv labels/sv2_frames/sv2_shrunk\n",
      "frame 3 of video in /home/nripstein/Documents/thesis data/thesis labels/sv labels/sv2_frames/sv2_shrunk\n",
      "frame 4 of video in /home/nripstein/Documents/thesis data/thesis labels/sv labels/sv2_frames/sv2_shrunk\n",
      "frame 5 of video in /home/nripstein/Documents/thesis data/thesis labels/sv labels/sv2_frames/sv2_shrunk\n",
      "frame 6 of video in /home/nripstein/Documents/thesis data/thesis labels/sv labels/sv2_frames/sv2_shrunk\n",
      "frame 7 of video in /home/nripstein/Documents/thesis data/thesis labels/sv labels/sv2_frames/sv2_shrunk\n",
      "frame 8 of video in /home/nripstein/Documents/thesis data/thesis labels/sv labels/sv2_frames/sv2_shrunk\n",
      "frame 9 of video in /home/nripstein/Documents/thesis data/thesis labels/sv labels/sv2_frames/sv2_shrunk\n",
      "frame 10 of video in /home/nripstein/Documents/thesis data/thesis labels/sv labels/sv2_frames/sv2_shrunk\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m fps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m60\u001b[39m  \u001b[38;5;66;03m# Adjust FPS as needed\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#  image_seq_to_segmentation_video(images_paths[i], baseline_segmentations[i], advanced_segmentations[i], gts[i], f'videos/{images_paths[i].split(\"/\")[-1]}.mp4')\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# If your DataFrame includes multiple videos, you might need to loop through them here\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[43mimage_seq_to_segmentation_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msv2_pred.png\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msv2_pred.png\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msv2_gt.png\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfps\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[61], line 64\u001b[0m, in \u001b[0;36mimage_seq_to_segmentation_video\u001b[0;34m(images_path, baseline_path, v2_path, gts, output_path, fps)\u001b[0m\n\u001b[1;32m     62\u001b[0m     img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(images_path, filename))\n\u001b[1;32m     63\u001b[0m     height, width, layers \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m---> 64\u001b[0m     image_with_segmentation \u001b[38;5;241m=\u001b[39m add_segmentation(img, i, base, v2, num_frames, \u001b[43mgts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     65\u001b[0m     img_array\u001b[38;5;241m.\u001b[39mappend(image_with_segmentation)\n\u001b[1;32m     67\u001b[0m size \u001b[38;5;241m=\u001b[39m (img_array[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], img_array[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[0;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "gts = sv2_merged[\"label\"]\n",
    "predictions = sv2_merged[\"contact_label_pred\"]\n",
    "images_path = sv2_dir + \"sv2_shrunk\"\n",
    "output_path = sv2_dir + 'video_with_predictions.mp4'\n",
    "fps = 60  # Adjust FPS as needed\n",
    "#  image_seq_to_segmentation_video(images_paths[i], baseline_segmentations[i], advanced_segmentations[i], gts[i], f'videos/{images_paths[i].split(\"/\")[-1]}.mp4')\n",
    "# If your DataFrame includes multiple videos, you might need to loop through them here\n",
    "image_seq_to_segmentation_video(images_path, \"sv2_pred.png\", \"sv2_pred.png\", \"sv2_gt.png\", output_path, fps=fps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can't figure out the above, so try vistal package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def csv_to_tuples(filename):\n",
    "    data = []\n",
    "    with open(filename, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        next(reader)  # Skip header row if it exists\n",
    "        for row in reader:\n",
    "            # Skip the first column and convert the rest to integers\n",
    "            holding_transitions, not_holding_transitions = map(int, row[1:])\n",
    "            data.append((holding_transitions, not_holding_transitions))\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "def get_last_indices_of_consecutive_labels2(df, transformation_dict):\n",
    "    last_indices = {}\n",
    "    last_label = None\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        current_label = row['contact_label_pred']\n",
    "        # If the current label is different from the last one, update the dictionary\n",
    "        if current_label != last_label:\n",
    "            if last_label is not None:  # to skip the very first label\n",
    "                # Transform the label using the transformation_dict\n",
    "                transformed_label = transformation_dict.get(last_label, last_label)\n",
    "                last_indices[last_index] = transformed_label\n",
    "            last_label = current_label\n",
    "        last_index = index  # keep track of the last index\n",
    "    \n",
    "    # Add the last label and index after the loop\n",
    "    # Transform the label using the transformation_dict\n",
    "    transformed_label = transformation_dict.get(current_label, current_label)\n",
    "    last_indices[last_index] = transformed_label\n",
    "\n",
    "    return last_indices\n",
    "\n",
    "from typing import List, Tuple\n",
    "def comparison_dicts(gt_transitions: List[tuple], max_len) -> Tuple[dict]:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        gt_transitions: List of tuples of ground truth transition frames in form [(start1, end1), (start2, end2) ...]\n",
    "    \"\"\"\n",
    "\n",
    "    def transition_to_dict(trns: List[Tuple[int, int]]) -> dict:\n",
    "        output_dict = {}\n",
    "        for bound in trns:\n",
    "            output_dict[bound[0]] = \"red\"\n",
    "            output_dict[bound[1]] = \"green\"\n",
    "        return output_dict\n",
    "    \n",
    "    trans_dict_gt = transition_to_dict(gt_transitions)\n",
    "    trans_dict_gt[max_len] = \"red\"  # need to make remaining frames without contact red\n",
    "    return trans_dict_gt\n",
    "\n",
    "def dict_tovistal_format(data):\n",
    "    prediction = []\n",
    "    start = 0\n",
    "    previous_label = None\n",
    "    for key in sorted(data.keys()):\n",
    "        end = key\n",
    "        label = data[key]\n",
    "        if label != previous_label:\n",
    "            if previous_label is not None:\n",
    "                prediction.append((start, end - 1, 0 if previous_label == 'red' else 1))\n",
    "            start = end\n",
    "            previous_label = label\n",
    "    # Adding the last segment\n",
    "    prediction.append((start, end, 0 if previous_label == 'red' else 1))\n",
    "    return prediction\n",
    "\n",
    "\n",
    "sv2_dir = \"/home/nripstein/Documents/thesis data/thesis labels/sv labels/sv2_frames/\"\n",
    "sv2_gt_tuples = csv_to_tuples(sv2_dir + \"changepoints.csv\")\n",
    "sv2_gt_tuples\n",
    "sv2_gt_dict = comparison_dicts(sv2_gt_tuples, max_len=len(sv2_pred))\n",
    "# display(sv2_gt_dict)\n",
    "\n",
    "transformation_dict = {\"Portable Object Contact\": \"green\", \"Portable Object\": \"green\", \"Stationary Object Contact\": \"red\", \"No Contact\": \"yellow\", \"Self Contact\": \"red\"}\n",
    "sv2_pred = pd.read_csv(sv2_dir + \"sv2_pred.csv\")\n",
    "sv2_pred = sv2_pred.rename(columns={\"image\": \"frame_id\", \"contact_label\": \"contact_label_pred\"})\n",
    "sv2_pred_dict = get_last_indices_of_consecutive_labels2(sv2_pred, transformation_dict)\n",
    "# display(sv2_pred_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv2_gt_vistal = dict_tovistal_format(sv2_gt_dict)\n",
    "sv2_pred_vistal = dict_tovistal_format(sv2_pred_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subtitle saved to /home/nripstein/Documents/thesis data/thesis labels/sv labels/sv2_frames/tutorial.ass.\n"
     ]
    }
   ],
   "source": [
    "from vistal import vistal, ColourScheme, Colour\n",
    "\n",
    "colour_scheme = ColourScheme(\n",
    "    colours=[\n",
    "        Colour(b=0, g=0,   r=255),\n",
    "        Colour(b=0, g=255, r=0),\n",
    "    ]\n",
    ")\n",
    "\n",
    "display_width = 480 * 2\n",
    "display_height = 480 * 2\n",
    "video_duration = 6 # 60 * len(sv2_pred) # > 9 is error???!!\n",
    "\n",
    "sub = vistal(\n",
    "    temporal_list_dict={\n",
    "        'gt  ': sv2_gt_vistal,\n",
    "        'pred': sv2_pred_vistal\n",
    "    },\n",
    "    label_names=[\"Non-Contact\", \"Contact\"],\n",
    "    colour_scheme=colour_scheme,\n",
    "    video_duration=video_duration,\n",
    "    display_width=display_width,\n",
    "    display_height=display_height,\n",
    "    timeline_height=72,\n",
    "    font_size=72,\n",
    "    font_name='Ubuntu Mono',\n",
    "    show_legend=True,\n",
    ")\n",
    "\n",
    "sub.save(sv2_dir + 'tutorial.ass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7262/2675192459.py:47: RuntimeWarning: invalid value encountered in cast\n",
      "  pred=predictions.map({\"Portable Object\": 1, \"No Contact\": 0 , \"Stationary Object Contact\": 0}).to_numpy().astype(np.int8),\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt # visual from MS-TCN and diffact https://github.com/Finspire13/DiffAct/blob/main/utils.py\n",
    "def plot_barcode(class_num, gt=None, pred=None, show=True, save_file=None):\n",
    "\n",
    "    if class_num <= 10:\n",
    "        color_map = plt.cm.tab10\n",
    "    elif class_num > 20:\n",
    "        color_map = plt.cm.gist_ncar\n",
    "    else:\n",
    "        color_map = plt.cm.tab20\n",
    "\n",
    "    axprops = dict(xticks=[], yticks=[], frameon=False)\n",
    "    barprops = dict(aspect='auto', cmap=color_map, \n",
    "                interpolation='nearest', vmin=0, vmax=class_num-1)\n",
    "\n",
    "    fig = plt.figure(figsize=(18, 4))\n",
    "\n",
    "    # a horizontal barcode\n",
    "    if gt is not None:\n",
    "        ax1 = fig.add_axes([0, 0.45, 1, 0.2], **axprops)\n",
    "        ax1.set_title('Ground Truth')\n",
    "        ax1.imshow(gt.reshape((1, -1)), **barprops)\n",
    "\n",
    "    if pred is not None:\n",
    "        ax2 = fig.add_axes([0, 0.15, 1, 0.2], **axprops)\n",
    "        ax2.set_title('Predicted')\n",
    "        ax2.imshow(pred.reshape((1, -1)), **barprops)\n",
    "\n",
    "    if save_file is not None:\n",
    "        fig.savefig(save_file, dpi=400)\n",
    "    if show:\n",
    "        plt.show()\n",
    "    plt.close()\n",
    "\n",
    "# Example data\n",
    "gt_data = np.array([0, 1, 1, 2, 2, 3, 3, 3])  # Ground truth segmentation\n",
    "pred_data = np.array([0, 1, 1, 1, 2, 2, 3, 3])  # Predicted segmentation\n",
    "\n",
    "gts = sv2_merged[\"label\"]\n",
    "predictions = sv2_merged[\"contact_label_pred\"]\n",
    "\n",
    "\n",
    "\n",
    "transformation_dict = {\"Portable Object Contact\": \"green\", \"Portable Object\": \"green\", \"Stationary Object Contact\": \"red\", \"No Contact\": \"yellow\", \"Self Contact\": \"red\"}\n",
    "# Calling the function\n",
    "plot_barcode(class_num=20,\n",
    "             gt=gts.map({\"not_holding\": 0, \"holding\": 1}).to_numpy().astype(np.int8),\n",
    "             pred=predictions.map({\"Portable Object\": 1, \"No Contact\": 0 , \"Stationary Object Contact\": 0}).to_numpy().astype(np.int8),\n",
    "             show=True,\n",
    "             save_file=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABxwAAABkCAYAAAC8R0W7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8WgzjOAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEKklEQVR4nO3bQWrDMBRAQan0/ldWV4GQbsSjqm2YWZugYPk7zsNzrbUGAAAAAAAAQPB19QIAAAAAAACA5xIcAQAAAAAAgExwBAAAAAAAADLBEQAAAAAAAMgERwAAAAAAACATHAEAAAAAAIBMcAQAAAAAAAAywREAAAAAAADIBEcAAAAAAAAg+94+cs6Dy2DHXGOsg6dhrnOfDTtO7m/u5TVv7n7OT8/d3TWM8Xsdr7WZ3Zzy2l9XXwO7dubK+3XzlO/FPb3vt905fGJmuw/wF8xD+D+fv0HMcJ7CvYKn230GPP1/lbnPU62xt3m94QgAAAAAAABkgiMAAAAAAACQCY4AAAAAAABAJjgCAAAAAAAAmeAIAAAAAAAAZIIjAAAAAAAAkAmOAAAAAAAAQCY4AgAAAAAAAJngCAAAAAAAAGSCIwAAAAAAAJAJjgAAAAAAAEAmOAIAAAAAAACZ4AgAAAAAAABkgiMAAAAAAACQCY4AAAAAAABAJjgCAAAAAAAAmeAIAAAAAAAAZIIjAAAAAAAAkAmOAAAAAAAAQCY4AgAAAAAAAJngCAAAAAAAAGSCIwAAAAAAAJAJjgAAAAAAAEAmOAIAAAAAAACZ4AgAAAAAAABkgiMAAAAAAACQCY4AAAAAAABAJjgCAAAAAAAAmeAIAAAAAAAAZIIjAAAAAAAAkAmOAAAAAAAAQCY4AgAAAAAAAJngCAAAAAAAAGSCIwAAAAAAAJAJjgAAAAAAAEAmOAIAAAAAAACZ4AgAAAAAAABkgiMAAAAAAACQCY4AAAAAAABAJjgCAAAAAAAAmeAIAAAAAAAAZIIjAAAAAAAAkAmOAAAAAAAAQCY4AgAAAAAAAJngCAAAAAAAAGSCIwAAAAAAAJAJjgAAAAAAAEAmOAIAAAAAAACZ4AgAAAAAAABkgiMAAAAAAACQCY4AAAAAAABAJjgCAAAAAAAAmeAIAAAAAAAAZIIjAAAAAAAAkAmOAAAAAAAAQCY4AgAAAAAAAJngCAAAAAAAAGSCIwAAAAAAAJAJjgAAAAAAAEAmOAIAAAAAAACZ4AgAAAAAAABkgiMAAAAAAACQCY4AAAAAAABAJjgCAAAAAAAAmeAIAAAAAAAAZIIjAAAAAAAAkAmOAAAAAAAAQCY4AgAAAAAAAJngCAAAAAAAAGSCIwAAAAAAAJAJjgAAAAAAAEAmOAIAAAAAAACZ4AgAAAAAAABkgiMAAAAAAACQCY4AAAAAAABAJjgCAAAAAAAAmeAIAAAAAAAAZIIjAAAAAAAAkAmOAAAAAAAAQDbXWuvqRQAAAAAAAADP5A1HAAAAAAAAIBMcAQAAAAAAgExwBAAAAAAAADLBEQAAAAAAAMgERwAAAAAAACATHAEAAAAAAIBMcAQAAAAAAAAywREAAAAAAADIBEcAAAAAAAAg+wEShjHBjRryEQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABxwAAABkCAYAAAC8R0W7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8WgzjOAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAD7klEQVR4nO3bsQ3DMAwAQSvI/iszKyiPBIbtu1oFG1HFQ2tm5gAAAAAAAAAIXmcPAAAAAAAAAFyX4AgAAAAAAABkgiMAAAAAAACQCY4AAAAAAABAJjgCAAAAAAAAmeAIAAAAAAAAZIIjAAAAAAAAkAmOAAAAAAAAQCY4AgAAAAAAANl7++RafxyDHWvOngB+a6wVbsJ+5k7sZp7C7uaJ7Hj4nveCJ/NucHd2POyZY++y+OEIAAAAAAAAZIIjAAAAAAAAkAmOAAAAAAAAQCY4AgAAAAAAAJngCAAAAAAAAGSCIwAAAAAAAJAJjgAAAAAAAEAmOAIAAAAAAACZ4AgAAAAAAABkgiMAAAAAAACQCY4AAAAAAABAJjgCAAAAAAAAmeAIAAAAAAAAZIIjAAAAAAAAkAmOAAAAAAAAQCY4AgAAAAAAAJngCAAAAAAAAGSCIwAAAAAAAJAJjgAAAAAAAEAmOAIAAAAAAACZ4AgAAAAAAABkgiMAAAAAAACQCY4AAAAAAABAJjgCAAAAAAAAmeAIAAAAAAAAZIIjAAAAAAAAkAmOAAAAAAAAQCY4AgAAAAAAAJngCAAAAAAAAGSCIwAAAAAAAJAJjgAAAAAAAEAmOAIAAAAAAACZ4AgAAAAAAABkgiMAAAAAAACQCY4AAAAAAABAJjgCAAAAAAAAmeAIAAAAAAAAZIIjAAAAAAAAkAmOAAAAAAAAQCY4AgAAAAAAAJngCAAAAAAAAGSCIwAAAAAAAJAJjgAAAAAAAEAmOAIAAAAAAACZ4AgAAAAAAABkgiMAAAAAAACQCY4AAAAAAABAJjgCAAAAAAAAmeAIAAAAAAAAZIIjAAAAAAAAkAmOAAAAAAAAQCY4AgAAAAAAAJngCAAAAAAAAGSCIwAAAAAAAJAJjgAAAAAAAEAmOAIAAAAAAACZ4AgAAAAAAABkgiMAAAAAAACQCY4AAAAAAABAJjgCAAAAAAAAmeAIAAAAAAAAZIIjAAAAAAAAkAmOAAAAAAAAQCY4AgAAAAAAAJngCAAAAAAAAGSCIwAAAAAAAJAJjgAAAAAAAEAmOAIAAAAAAACZ4AgAAAAAAABkgiMAAAAAAACQCY4AAAAAAABAJjgCAAAAAAAAmeAIAAAAAAAAZIIjAAAAAAAAkAmOAAAAAAAAQCY4AgAAAAAAAJngCAAAAAAAAGSCIwAAAAAAAJAJjgAAAAAAAEC2ZmbOHgIAAAAAAAC4Jj8cAQAAAAAAgExwBAAAAAAAADLBEQAAAAAAAMgERwAAAAAAACATHAEAAAAAAIBMcAQAAAAAAAAywREAAAAAAADIBEcAAAAAAAAgExwBAAAAAACA7AMwrRPBof0YDgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import matplotlib.colors\n",
    "def plot_barcode(gt=None, pred=None, show=True, save_file=None):\n",
    "    red = np.array([1, 0, 0, 1])\n",
    "    green = np.array([0, 1, 0, 1])\n",
    "    colors = [red, green]\n",
    "    color_map = LinearSegmentedColormap.from_list(\"Custom\", colors, N=2)\n",
    "    # color_map = matplotlib.colors.ListedColormap(['red', 'green'])\n",
    "\n",
    "    axprops = dict(xticks=[], yticks=[], frameon=False)\n",
    "    barprops = dict(aspect='auto', cmap=color_map, \n",
    "                interpolation='nearest', vmin=0, vmax=1)\n",
    "\n",
    "    fig = plt.figure(figsize=(18, 4))\n",
    "\n",
    "    # a horizontal barcode\n",
    "    if gt is not None:\n",
    "        ax1 = fig.add_axes([0, 0.45, 1, 0.2], **axprops)\n",
    "        ax1.set_title('Ground Truth')\n",
    "        ax1.imshow(gt.reshape((1, -1)), **barprops)\n",
    "\n",
    "    if pred is not None:\n",
    "        ax2 = fig.add_axes([0, 0.15, 1, 0.2], **axprops)\n",
    "        # ax2.set_title('Predicted')\n",
    "        ax2.imshow(pred.reshape((1, -1)), **barprops)\n",
    "\n",
    "    if save_file is not None:\n",
    "        fig.savefig(save_file, dpi=400)\n",
    "    if show:\n",
    "        plt.show()\n",
    "    plt.close()\n",
    "\n",
    "plot_barcode(\n",
    "             gt=None,\n",
    "             pred=predictions.map({\"Portable Object\": 1, \"Self Contact\": 0, \"No Contact\": 0 , \"Stationary Object Contact\": 0}).to_numpy().astype(bool),\n",
    "             show=True,\n",
    "             save_file=\"sv2_pred.png\")\n",
    "\n",
    "plot_barcode(\n",
    "             gt=None,\n",
    "             pred=gts.map({\"not_holding\": 0, \"holding\": 1}).to_numpy().astype(np.int8),\n",
    "             show=True,\n",
    "             save_file=\"sv2_gt.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ...,  True,  True,  True])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.map({\"Portable Object\": 1, \"Self Contact\": 0, \"No Contact\": 0 , \"Stationary Object Contact\": 0}).to_numpy().astype(bool)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shan_et_al2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
